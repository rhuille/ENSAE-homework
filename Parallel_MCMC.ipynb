{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"logo_ensae.png\" style=\"float:right;width:30%\"> </img>\n",
    "<p style=\"font-size:2em;\">Parallel MCMC </p>\n",
    "<p style=\"font-size:1.5em\">Eléments logiciels pour le traitement des données massives </p>\n",
    "http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx/projet_info_3A.html\n",
    "\n",
    "Raphaël Huille & Michael Sok <br>\n",
    "ENSAE ParisTech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons choisi d'implémenter l'algorithme Independent Metropolis–Hastings (IMH) décrit dans l'article : \n",
    "[*Using parallel computation to improve Independent Metropolis–Hastings based estimation* (2011)](https://arxiv.org/pdf/1010.1595v3.pdf) en utilisant la fonction *Pool* du pkg *multiprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time, sleep\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IMH(object):\n",
    "    \"\"\"\n",
    "    Class IMH\n",
    "    #########\n",
    "    \n",
    "    Implementation of IMH (Independent Metropolis Hasting) algorithm explained in :\n",
    "    << Using parallel computation to improve Independent Metropolis Hasting based estimation >>\n",
    "    Jacob and al. 2011\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    - omega (function) : density function of the distribution to simulate\n",
    "    - gen_candidate (function(N) ) : reurn an array of N values gen from the candidate distribution\n",
    "\n",
    "    - x0 (float) : initialisation\n",
    "    - N (int) : length of the markov chain\n",
    "    - njobs (int) : \n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    - compute_permutation : Return the permuted index 1,2,...,n according to self.permutation method\n",
    "    - fit_simple : implementation of the fundamental version of the IMH algorithm \n",
    "    - fit_block : implementation of the block version of the IMH algorithm \n",
    "    - fit : main method interface\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, omega, gen_candidate) :\n",
    "        self.omega = np.vectorize(omega)\n",
    "        self.gen_candidate = gen_candidate\n",
    "\n",
    "    def compute_permutation(self, n):\n",
    "\n",
    "        if self.permutation == \"same_order\":\n",
    "            return_list = [list(range(1,n))]*self.njobs\n",
    "        elif self.permutation == \"random\": \n",
    "            return_list=[list(np.random.permutation(n)) for i in range(self.njobs)]\n",
    "        else:\n",
    "            print(\"error : permutation must be 'same_order' or 'random' \")\n",
    "        return(return_list)\n",
    "\n",
    "\n",
    "    def fit_simple(self, b=0):\n",
    "\n",
    "        n = self.y.shape[0] # either equal to : \n",
    "                            # - self.N (when method ='simple')\n",
    "                            # - self.nblocks (when method ='parallel')\n",
    "        \n",
    "        \n",
    "        i = np.random.permutation(self.nblocks)\n",
    "        i = [0]+list(i)\n",
    "        # go\n",
    "        current = 0\n",
    "        weight = np.full(fill_value = 0, shape = n)\n",
    "        for candidate in range(1, len(i)):\n",
    "            ratio = min(1, self.omega_y[i[candidate],b]/self.omega_y[i[current],b])\n",
    "            u = np.random.binomial(1,ratio)\n",
    "            current += u*(candidate-current) # current is updated to candidate if u = 1 \n",
    "                                             # and stay current if u = 0\n",
    "\n",
    "            weight[i[current]] += 1 # add current value to the chain\n",
    "        \n",
    "        return weight\n",
    "\n",
    "    \n",
    "    def fit_block(self):\n",
    "        \n",
    "        weight = np.full(fill_value = 0, shape = self.y.shape)\n",
    "        with Pool(self.njobs) as p:\n",
    "            for b in range(self.B): \n",
    "\n",
    "                weight_block = np.array(p.map(self.fit_simple, [b]*self.njobs))\n",
    "                weight[:,b] = weight_block.sum(axis = 0)\n",
    "\n",
    "                if b < self.B-1 : # init the next block picking randomly in the current block\n",
    "                    self.y[0,b+1] = np.random.choice(self.y[1:,b], size=1, p= weight[1:,b]/weight[1:,b].sum())\n",
    "                    self.omega_y[0,b+1] = self.omega(self.y[0,b+1])\n",
    "        return weight\n",
    "\n",
    "\n",
    "    def fit(self, x0, N, method = 'simple', B = 1, njobs = 1):\n",
    "        self.B = B\n",
    "        self.nblocks = int(N/B)\n",
    "        self.njobs = njobs\n",
    "        self.N = N     \n",
    "\n",
    "        if method == \"simple\":            \n",
    "            # (1) creation of candidate sample\n",
    "            self.y = np.reshape(self.gen_candidate(self.N-1), newshape=(self.N-1,1))\n",
    "            # (2) add init value\n",
    "            self.y = np.append([[x0]], self.y, axis = 0)\n",
    "            # (3) computation of omega values\n",
    "            self.omega_y = self.omega(self.y)\n",
    "            # (4) computation of weight with IMH algo\n",
    "            self.weights = self.fit_simple()\n",
    "            \n",
    "        elif method == 'parallel':\n",
    "            # (1) creation of candidate sample\n",
    "            self.y = np.array(Pool(njobs).map(self.gen_candidate,[int(self.N/njobs)]*njobs))\n",
    "            # (3) computation of omega values\n",
    "            self.omega_y = np.array(Pool(njobs).map(self.omega, list(self.y)))\n",
    "            \n",
    "            # reshape : this is usefull when nblocks!=njobs\n",
    "            self.y = np.reshape(self.y, newshape=(self.nblocks, self.B))\n",
    "            self.omega_y = np.reshape(self.omega_y,newshape=(self.nblocks, self.B))\n",
    "            # (2) add init value\n",
    "            self.y = np.append(np.full((1,self.B), x0), self.y, axis = 0)\n",
    "            self.omega_y = np.append(np.full((1,self.B), self.omega(x0)), self.omega_y, axis = 0)\n",
    "            \n",
    "            # (4) computation of weight with IMH algo\n",
    "            self.weights = self.fit_block() # computation of weight\n",
    "        \n",
    "        self.weights = np.reshape(self.weights,newshape=self.y.shape)\n",
    "        self.expectation = np.average(self.y[1:,:], weights= self.weights[1:,:])\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va simuler une loi normale de moyenne égale à 3. <br> \n",
    "La loi candidate sera une cauchy centrée en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "def omega(x):  # densité de la loi normale\n",
    "    return((1+x**2)*np.exp(-(x)**2/2))\n",
    "\n",
    "def gen_candidate(N):\n",
    "    np.random.seed() # for seeding the generator\n",
    "    return np.random.standard_cauchy(size = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMH_computer  = IMH(omega, gen_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation de la moyenne avec la methode simple :  0.00507782535995\n",
      "Estimation de la moyenne avec la methode parallel :  -0.0232835264956\n"
     ]
    }
   ],
   "source": [
    "IMH_computer.fit(x0 = 0, N = 4000, method='simple')\n",
    "print(\"Estimation de la moyenne avec la methode simple : \", IMH_computer.expectation)\n",
    "\n",
    "IMH_computer.fit(x0 = 0, N = 4000, method='parallel', B=10, njobs=4)\n",
    "print(\"Estimation de la moyenne avec la methode parallel : \", IMH_computer.expectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les estimations de la moyenne semblent correct ! <br>\n",
    "Evaluons maintenant les performances des deux méthodes selon 2 critères : \n",
    "- le temps d'execution\n",
    "- la variances de l'estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temps d'execution :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.6 ms ± 752 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 -r 3 IMH_computer.fit(x0 = 0, N = 4000, method='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 ms ± 4.27 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 3 -r 3 IMH_computer.fit(x0 = 0, N = 4000, method='parallel', B=10, njobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04640096912745427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_simple = []\n",
    "for i in range(1000):\n",
    "    IMH_computer.fit(x0 = 0, N = 40, method='simple')\n",
    "    estimation_simple += [IMH_computer.expectation]\n",
    "    \n",
    "np.var(estimation_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0360482433817058"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_parallel= []\n",
    "for i in range(10):\n",
    "    IMH_computer.fit(x0 = 0, N = 40, method='parallel', B=10, njobs=4)\n",
    "    estimation_parallel += [IMH_computer.expectation]\n",
    "\n",
    "np.var(estimation_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nombre *N* de candidats égaux, la méthode *parallel* donnera un estimateur de **variance plus faible** que l'estimateur obtenu avec la méthode *simple*. Néanmoins, à nombre *N* de candidats égaux, **la méthode *parallel* aura un temps d'execution un peu plus long que la méthode *simple* ** car elle execute plus de calcul. Cela se traduit les sommes des poids obtenus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMH_computer.fit(x0 = 0, N = 4000, method='parallel', B=10, njobs=4).weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMH_computer.fit(x0 = 0, N = 4000, method='simple').weights.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La somme est plus grande pour la méthode *parallel* : plus de chaines de Markov ont été généré avec les candidats qu'avec la méthode *parallel*. D'où la variance plus petite mais le temps d'excution plus long !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux critères - variance et temps - sont liées par le paramètre *N* : en effet, plus *N* est grand, plus la variance sera faible mais plus le temps d'execution sera long. On pourrait donc utiliser la méthode parallèle pour avoir un estimateur plus rapide, mais à variance égale qu'avec la méthode simple... Reste à savoir si le gain de performance variance de la methode *parrallel* compense la perte de performance en temps ... Cela dépend grandement de l'ordinateur utilisé ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
